{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages Used"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 1,
>>>>>>> main
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset to get the year from 2014-2020"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 2,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "/var/folders/p6/58mjrc3j36xb6l4d32z_8h000000gn/T/ipykernel_81075/2665248475.py:1: DtypeWarning: Columns (14,15,16,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
=======
      "/var/folders/p6/58mjrc3j36xb6l4d32z_8h000000gn/T/ipykernel_61151/2435295531.py:1: DtypeWarning: Columns (14,15,16,21) have mixed types. Specify dtype option on import or set low_memory=False.\n",
>>>>>>> main
      "  new_df = pd.read_csv(\"New Dataset.csv\")\n"
     ]
    }
   ],
   "source": [
    "new_df = pd.read_csv(\"New Dataset.csv\")\n",
    "\n",
    "# Renaming the columns as our need\n",
    "new_df = new_df.rename(columns={'Event':'Disaster','Date (YMD)':'Date','&quot;Code Province&quot;':'Code Region','&quot;Code District&quot;':'Code District',\n",
    "                                '&quot;Code Division&quot;':'Code Commune','&quot;Division&quot;':'Location'})\n",
    "\n",
<<<<<<< HEAD
    "comb_needed = ['Serial','Disaster','Code Region','Code District','Code Commune','Location','Date']\n",
=======
    "comb_needed = ['Disaster','Code Region','Code District','Code Commune','Location','Date']\n",
>>>>>>> main
    "\n",
    "new_df = new_df[comb_needed]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset to get the year from 2000-2014"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 3,
>>>>>>> main
   "metadata": {},
   "outputs": [],
   "source": [
    "old_df = pd.read_csv(\"Original Dataset.csv\")\n",
    "\n",
    "# Renaming the columns as our need\n",
    "old_df = old_df.rename(columns={'Event':'Disaster','Date (YMD)':'Date'})\n",
<<<<<<< HEAD
    "needed_columns = ['Serial','Disaster','Code Region','Code District','Code Commune','Location','Date']\n",
=======
    "needed_columns = ['Disaster','Code Region','Code District','Code Commune','Location','Date']\n",
>>>>>>> main
    "\n",
    "old_df=old_df[needed_columns]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine both datasets and remove duplicates"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 4,
>>>>>>> main
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([old_df,new_df],ignore_index=True)\n",
    "combined_df = combined_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only the needed disasters"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 5,
>>>>>>> main
   "metadata": {},
   "outputs": [],
   "source": [
    "df = combined_df\n",
    "\n",
    "disasters = ['FLOOD','CYCLONE & FLOOD','FLASH FLOOD','URBAN FLOOD','COASTLINE','LANDSLIDE','LAND SUBSIDENCE',\n",
    "            'CYCLONE','Collapse of Mine','COASTLINE','GALE','HAILSTORM','STORM','STRONG WIND','TIDAL WAVE','TORNADO',\n",
    "            'ROCK FALL','EARTH SLIP','HEAVY RAINS','Subsidence','Collapse of Gabage Fill']\n",
    "df = df[df[\"Disaster\"].isin(disasters)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select only the years after 2000. \n",
    "Insert another two columns for month and year"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 6,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "/var/folders/p6/58mjrc3j36xb6l4d32z_8h000000gn/T/ipykernel_81075/1070540146.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'],errors='coerce')\n",
      "/var/folders/p6/58mjrc3j36xb6l4d32z_8h000000gn/T/ipykernel_81075/1070540146.py:1: SettingWithCopyWarning: \n",
=======
      "/var/folders/p6/58mjrc3j36xb6l4d32z_8h000000gn/T/ipykernel_61151/1070540146.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date'] = pd.to_datetime(df['Date'],errors='coerce')\n",
      "/var/folders/p6/58mjrc3j36xb6l4d32z_8h000000gn/T/ipykernel_61151/1070540146.py:1: SettingWithCopyWarning: \n",
>>>>>>> main
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Date'] = pd.to_datetime(df['Date'],errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'],errors='coerce')\n",
    "\n",
    "df = df[(df['Date'].dt.year >= 2000) & (df['Date'].dt.year <=2021)].copy()\n",
    "\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "\n",
    "# To omit time value from date\n",
    "df['Date'] = df['Date'].dt.date\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping the Districts to the District Codes"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 7,
>>>>>>> main
   "metadata": {},
   "outputs": [],
   "source": [
    "districts = {\n",
    "    'lka001001':'Colombo',\n",
    "    'lka001002':'Gampaha',\n",
    "    'lka001003':'Kaluthara',\n",
    "    'lka002001':'Kandy',\n",
    "    'lka002002':'Matale',\n",
    "    'lka002003':'Nuwara Eliya',\n",
    "    'lka003001':'Galle',\n",
    "    'lka003002':'Matara',\n",
    "    'lka003003':'Hambantota',\n",
    "    'lka004001':'Jaffna',\n",
    "    'lka004002':'Mannar',\n",
    "    'lka004003':'Vavuniya',\n",
    "    'lka004004':'Mullaitivu',\n",
    "    'lka004005':'Kilinochchi',\n",
    "    'lka005001':'Batticaloa',\n",
    "    'lka005002':'Ampara',\n",
    "    'lka005003':'Trincomalee',\n",
    "    'lka006001':'Kurunegala',\n",
    "    'lka006002':'Puttalam',\n",
    "    'lka007001':'Anuradhapura',\n",
    "    'lka007002':'Polannaruwa',\n",
    "    'lka008001':'Badulla',\n",
    "    'lka008002':'Monaragala',\n",
    "    'lka009001':'Ratnapura',\n",
    "    'lka009002':'Kegalle'\n",
    "}\n",
    "\n",
    "df['District'] = df['Code District'].map(districts)\n",
    "\n",
<<<<<<< HEAD
    "col_order = ['Serial', 'Disaster', 'Code Region', 'Code District', 'Code Commune', 'Location',\n",
=======
    "col_order = ['Disaster', 'Code Region', 'Code District', 'Code Commune', 'Location',\n",
>>>>>>> main
    "            'District', 'Date', 'Year', 'Month']\n",
    "\n",
    "df = df[col_order]\n",
    "df.sort_values(by=\"Date\").to_csv(\"Preprocessed.csv\",index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
